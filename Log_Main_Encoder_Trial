

Description: 
------------
Testing the encoder part along with the embedding with
all the frames: past frames and future frames

-----------------------------------------------------------------------------



- Shape of the sample_original is: torch.Size([10000, 29]) 

- Random integer:  26 

- Sample shape after squeezing and slicing is : torch.Size([1, 1, 4, 29]) 

----------- Convolution Size Variation through layers       -------------- 

--> Initial sizes are: 
 height =  4 and width =  29 

-> After Conv layer # 0 
 height =  4 and width =  29 

-> After pooling layer # 0 
 height =  4 and width =  15 

-> After Conv layer # 1 
 height =  4 and width =  15 

-> After pooling layer # 1 
 height =  4 and width =  8 

-> After Conv layer # 2 
 height =  4 and width =  8 

-> After pooling layer # 2 
 height =  4 and width =  4 

-> After Conv layer # 3 
 height =  4 and width =  4 

-> After pooling layer # 3 
 height =  4 and width =  2 

---------------------------- 

----------- Encoder Architecture -------------- 

Printing the CNN Model layers name and their corresponding              shape: 

encoder.0.0.weight 	 	 torch.Size([64, 1, 3, 3]) 

encoder.0.0.bias 	 	 torch.Size([64]) 

encoder.0.1.weight 	 	 torch.Size([64]) 

encoder.0.1.bias 	 	 torch.Size([64]) 

encoder.1.0.weight 	 	 torch.Size([128, 64, 3, 3]) 

encoder.1.0.bias 	 	 torch.Size([128]) 

encoder.1.1.weight 	 	 torch.Size([128]) 

encoder.1.1.bias 	 	 torch.Size([128]) 

encoder.2.0.weight 	 	 torch.Size([256, 128, 3, 3]) 

encoder.2.0.bias 	 	 torch.Size([256]) 

encoder.2.1.weight 	 	 torch.Size([256]) 

encoder.2.1.bias 	 	 torch.Size([256]) 

encoder.3.0.weight 	 	 torch.Size([256, 256, 3, 3]) 

encoder.3.0.bias 	 	 torch.Size([256]) 

encoder.3.1.weight 	 	 torch.Size([256]) 

encoder.3.1.bias 	 	 torch.Size([256]) 

dense_part.0.0.weight 	 	 torch.Size([128, 256]) 

dense_part.0.0.bias 	 	 torch.Size([128]) 

---------------------------- 

-- > Testing forward propagation through encoder part 

--> Tensor shape before encoder part: torch.Size([1, 1, 4, 29]) 

--> Tensor shape after encoder part: torch.Size([1, 256, 4, 4]) 

--> Done testing shape for encoder part ! 

- Prediction shape is torch.Size([4, 128]) 
