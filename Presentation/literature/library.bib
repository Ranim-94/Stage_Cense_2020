Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Dataset_Imagenet,
author = {Takamitsu, Y. and Orita, Y.},
doi = {10.14842/jpnjnephrol1959.20.1221},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Literature/1{\_}Citation{\_}Papers/imagenet.pdf:pdf},
issn = {03852385},
journal = {Japanese Journal of Nephrology},
number = {11},
pages = {1221--1227},
title = {{Effect of glomerular change on the electrolyte reabsorption of the renal tubule in glomerulonephritis (author's transl)}},
volume = {20},
year = {1978}
}
@book{LIDAR_CRC,
author = {{Dong, Pinliang , Chen}, Qi},
file = {:E$\backslash$:/1{\_}Master Feuilles et Documents/PHD{\_}Offers/UK/LIDAR remote Sensing and Application.pdf:pdf},
isbn = {9781482243017},
pages = {197},
title = {{LiDAR Remote Sensing and Applications}},
year = {2018}
}
@article{AlexNet,
abstract = {Delineating the tremendous growth in this area, the Handbook of Approximation Algorithms and Metaheuristics covers fundamental, theoretical topics as well as advanced, practical applications. It is the first book to comprehensively study both approximation algorithms and metaheuristics. Starting with basic approaches, the handbook presents the methodologies to design and analyze efficient approximation algorithms for a large class of problems, and to establish inapproximability results for another class of problems. It also discusses local search, neural networks, and metaheuristics, as well as multiobjective problems, sensitivity analysis, and stability. After laying this foundation, the book applies the methodologies to classical problems in combinatorial optimization, computational geometry, and graph problems. In addition, it explores large-scale and emerging applications in networks, bioinformatics, VLSI, game theory, and data analysis. Undoubtedly sparking further developments in the field, this handbook provides the essential techniques to apply approximation algorithms and metaheuristics to a wide range of problems in computer science, operations research, computer engineering, and economics. Armed with this information, researchers can design and analyze efficient algorithms to generate near-optimal solutions for a wide range of computational intractable problems.},
author = {Gonzalez, Teofilo F.},
doi = {10.1201/9781420010749},
file = {:C$\backslash$:/Users/USER/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gonzalez - 2007 - Handbook of approximation algorithms and metaheuristics(2).pdf:pdf},
isbn = {9781420010749},
journal = {Handbook of Approximation Algorithms and Metaheuristics},
pages = {1--1432},
title = {{Handbook of approximation algorithms and metaheuristics}},
year = {2007}
}
@article{ReLu,
abstract = {A typical gait analysis data collection consists of a series of discrete trials, where a participant initiates gait, walks through a motion capture volume, and then terminates gait. This is not a normal ‘everyday' gait pattern, yet measurements are considered representative of normal walking. However, walking speed, a global descriptor of gait quality that can affect joint kinematics and kinetics, may be different during discrete trials, compared to continuous walking. Therefore, the purpose of this study was to investigate the effect of continuous walking versus discrete trials on walking speed and walking speed variability. Data were collected for 25 healthy young adults performing 2 walking tasks. The first task represented a typical gait data collection session, where subjects completed repeated trials, beginning from a standstill and walking along a 12-m walkway. The second task was continuous walking along a “figure-of-8” circuit, with 1 section containing the same 12-m walkway. Walking speed was significantly higher during the discrete trials compared to the continuous trials (p {\textless} .001), but there were no significant differences in walking speed variability between the conditions. The results suggest that choice of gait protocol may affect results where variables are sensitive to walking speed.},
author = {Brown, Marcus J. and Hutchinson, Laura A. and Rainbow, Michael J. and Deluzio, Kevin J. and {De Asha}, Alan R.},
doi = {10.1123/jab.2016-0355},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Papers/1{\_}Citation{\_}Papers/reluICML.pdf:pdf},
issn = {15432688},
journal = {Journal of Applied Biomechanics},
keywords = {Gait,Methodology,Walking speed},
number = {5},
pages = {384--387},
title = {{A comparison of self-selected walking speeds and walking speed variability when data are collected during repeated discrete trials and during continuous walking}},
volume = {33},
year = {2017}
}
@article{CNN_Audio_Karol_Pickzak,
abstract = {This paper evaluates the potential of convolutional neural networks in classifying short audio clips of environmental sounds. A deep model consisting of 2 convolutional layers with max-pooling and 2 fully connected layers is trained on a low level representation of audio data (segmented spectro-grams) with deltas. The accuracy of the network is evaluated on 3 public datasets of environmental and urban recordings. The model outperforms baseline implementations relying on mel-frequency cepstral coefficients and achieves results com-parable to other state-of-the-art approaches.},
author = {Piczak, Karol J},
doi = {10.5281/zenodo.12714},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Literature/1{\_}Citation{\_}Papers/Piczak2015-ESC-ConvNet.pdf:pdf},
isbn = {9781467374545},
journal = {IEEE international workshop on machine learning for signal processing, Boston, USA},
keywords = {Index Terms— environmental sound,classification,convolutional neu-ral networks},
title = {{2015 Ieee International Workshop on Machine Learning for Signal Processing Environmental Sound Classification With Convolutional Neural Networks}},
year = {2015}
}
@article{ResNet,
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57{\%} error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28{\%} relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC {\&} COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
archivePrefix = {arXiv},
arxivId = {1512.03385},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
doi = {10.1109/CVPR.2016.90},
eprint = {1512.03385},
file = {:C$\backslash$:/Users/USER/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/He et al. - 2016 - Deep residual learning for image recognition.pdf:pdf},
isbn = {9781467388504},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {770--778},
title = {{Deep residual learning for image recognition}},
volume = {2016-Decem},
year = {2016}
}
@article{Context_Encoders,
archivePrefix = {arXiv},
arxivId = {arXiv:1604.07379v2},
author = {Pathak, Deepak and Donahue, Jeff},
eprint = {arXiv:1604.07379v2},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Literature/1{\_}Citation{\_}Papers/Context encoders Feature learning by inpainting.pdf:pdf},
title = {{Context Encoders: Feature Learning by Inpainting}}
}
@article{Dataset_Flickr,
abstract = {THE PHOTOGRAPH AND our understanding of photography transitioned from a world of unprocessed rolls of C-41 sitting in a refrigerator 50 years ago to sharing photos on the 1.5-inch screen of a point-and-shoot camera 10 years ago. Today, the photograph is again something different. The way we take photos has fundamentally changed from what it was. We can view, share, and interact with photos on the device that took them. We can edit, tag, or "filter" photos directly on the camera at the same time we take the photo. Photos can be automatically pushed to various online sharing services, and the distinction between photos and videos has lessened. Beyond this, and more important there are now lots of them. As of 2013, to Facebook alone more than 250 billion photos had been uploaded and on average received more than 350 million new photos each day,6 while YouTube reported in July 2015 that 300 hours of video were uploaded every minute.22 A back-of-the-envelope calculation estimated 10{\%} of all photos in the world were taken in the last 12 months, as of more than four years ago.},
archivePrefix = {arXiv},
arxivId = {1503.01817},
author = {Thomee, Bart and Elizalde, Benjamin and Shamma, David A. and Ni, Karl and Friedland, Gerald and Poland, Douglas and Borth, Damian and Li, And Li Jia},
doi = {10.1145/2812802},
eprint = {1503.01817},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Papers/ML{\_}Sound/Flickr{\_}SoundNet.pdf:pdf},
issn = {15577317},
journal = {Communications of the ACM},
number = {2},
pages = {64--73},
title = {{YFCC100M: The new data in multimedia research}},
volume = {59},
year = {2016}
}
@article{TRICYCLE,
author = {Cartwright, Mark and Cramer, Jason and Salamon, Justin and Bello, Juan Pablo},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Papers/2{\_}Tricycle.pdf:pdf},
number = {May},
title = {{TRICYCLE : AUDIO REPRESENTATION LEARNING FROM SENSOR NETWORK DATA USING SELF-SUPERVISION Music and Audio Research Laboratory , New York University , NYC , NY , USA Adobe Research , San Francisco , CA , USA}},
year = {2019}
}
@article{Dataset_ESC_50,
abstract = {One of the obstacles in research activities concentrating on environmental sound classification is the scarcity of suitable and publicly available datasets. This paper tries to address that issue by presenting a new annotated collection of 2 000 short clips comprising 50 classes of various common sound events, and an abundant unified compilation of 250 000 unla-beled auditory excerpts extracted from recordings available through the Freesound project. The paper also provides an evaluation of human accuracy in classifying environmen-tal sounds and compares it to the performance of selected baseline classifiers using features derived from mel-frequency cepstral coEffcients and zero-crossing rate.},
author = {Piczak, Karol J.},
doi = {10.1145/2733373.2806390},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Papers/Audio Data Sets/Piczak2015-ESC-Dataset.pdf:pdf},
isbn = {9781450334594},
journal = {MM 2015 - Proceedings of the 2015 ACM Multimedia Conference},
keywords = {Classification,Dataset,Environmental sound},
pages = {1015--1018},
title = {{ESC: Dataset for environmental sound classification}},
year = {2015}
}
@article{AudioSet,
abstract = {Audio event recognition, the human-like ability to identify and relate sounds from audio, is a nascent problem in machine perception. Comparable problems such as object detection in images have reaped enormous benefits from comprehensive datasets - principally ImageNet. This paper describes the creation of Audio Set, a large-scale dataset of manually-annotated audio events that endeavors to bridge the gap in data availability between image and audio research. Using a carefully structured hierarchical ontology of 632 audio classes guided by the literature and manual curation, we collect data from human labelers to probe the presence of specific audio classes in 10 second segments of YouTube videos. Segments are proposed for labeling using searches based on metadata, context (e.g., links), and content analysis. The result is a dataset of unprecedented breadth and size that will, we hope, substantially stimulate the development of high-performance audio event recognizers.},
author = {Gemmeke, Jort F. and Ellis, Daniel P.W. and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R. Channing and Plakal, Manoj and Ritter, Marvin},
doi = {10.1109/ICASSP.2017.7952261},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Papers/Audio Data Sets/AudioSet.pdf:pdf},
isbn = {9781509041176},
issn = {15206149},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
keywords = {Audio event detection,audio databases,data collection,sound ontology},
pages = {776--780},
title = {{Audio Set: An ontology and human-labeled dataset for audio events}},
year = {2017}
}
@article{Context_Prediction,
author = {Efros, Alexei A},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Literature/1{\_}Citation{\_}Papers/Doersch{\_}Unsupervised{\_}Visual{\_}Representation{\_}ICCV{\_}2015{\_}paper.pdf:pdf},
pages = {1422--1430},
title = {{Unsupervised Visual Representation Learning by Context Prediction}}
}
@article{L3_Original,
abstract = {We consider the question: what can be learnt by looking at and listening to a large number of unlabelled videos? There is a valuable, but so far untapped, source of information contained in the video itself -- the correspondence between the visual and the audio streams, and we introduce a novel "Audio-Visual Correspondence" learning task that makes use of this. Training visual and audio networks from scratch, without any additional supervision other than the raw unconstrained videos themselves, is shown to successfully solve this task, and, more interestingly, result in good visual and audio representations. These features set the new state-of-the-art on two sound classification benchmarks, and perform on par with the state-of-the-art self-supervised approaches on ImageNet classification. We also demonstrate that the network is able to localize objects in both modalities, as well as perform fine-grained recognition tasks.},
archivePrefix = {arXiv},
arxivId = {arXiv:1705.08168v2},
author = {Arandjelovic, Relja and Zisserman, Andrew},
doi = {10.1109/ICCV.2017.73},
eprint = {arXiv:1705.08168v2},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Papers/3{\_}L{\_}3{\_}Archtiecture.pdf:pdf},
isbn = {9781538610329},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {609--617},
title = {{Look, Listen and Learn}},
volume = {2017-Octob},
year = {2017}
}
@article{SONYC,
archivePrefix = {arXiv},
arxivId = {1805.00889},
author = {Bello, Juan P. and Silva, Claudio and Nov, Oded and {Luke Dubois}, R. and Arora, Anish and Salamon, Justin and Mydlarz, Charles and Doraiswamy, Harish},
doi = {10.1145/3224204},
eprint = {1805.00889},
file = {:C$\backslash$:/Users/USER/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bello et al. - 2019 - SonyC A system for monitoring, analyzing, and mitigating urban noise pollution.pdf:pdf},
issn = {15577317},
journal = {Communications of the ACM},
number = {2},
pages = {68--77},
title = {{SonyC: A system for monitoring, analyzing, and mitigating urban noise pollution}},
volume = {62},
year = {2019}
}
@book{Zhang2012,
abstract = {Numerical optimization is introduced as the mathematical foundation for this book, focusing on two basic unconstrained optimization algorithms: line search and trust-region methods. Line search optimization methods are relatively simple and commonly used gradient descent based methods. Their strength lies in their simplicity and ease of implementation, but their convergence properties degrade as the nonlinearity and complexity of the function to be optimized increases. Trust-region, or “restricted step” methods are presented as an often more practical alternative to line search that involved the construction of an approximation, or “model,” of the function to be minimized, together with a dynamic estimate of the region where this model is sufficiently valid. There are a large number of optimization methods, and the interested reader is referred to the bibliographical citations presented in this chapter. In this book we restrict our attention mainly to line search and trust-region methods, since we will use them in the context of their application to extremum seeking control and stability proofs thereof.},
author = {Zhang, Chunlei and Ord{\'{o}}{\~{n}}ez, Ra{\'{u}}l},
booktitle = {Advances in Industrial Control},
doi = {10.1007/978-1-4471-2224-1_2},
file = {:C$\backslash$:/Users/USER/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Ord{\'{o}}{\~{n}}ez - 2012 - Numerical optimization.pdf:pdf},
isbn = {0387987932},
issn = {21931577},
number = {9781447122234},
pages = {31--45},
title = {{Numerical optimization}},
year = {2012}
}
@article{DATA_DEPENDENT_CNN,
archivePrefix = {arXiv},
arxivId = {arXiv:1511.06856v3},
author = {Doersch, Carl and Donahue, Jeff and Darrell, Trevor and Science, Computer and Mellon, Carnegie},
eprint = {arXiv:1511.06856v3},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Literature/1{\_}Citation{\_}Papers/Datadependent.pdf:pdf},
title = {{DATA-DEPENDENT INITIALIZATIONS OF CONVOLUTIONAL NEURAL NETWORKS}},
year = {2016}
}
@book{Stat_for_Managers,
author = {{Levine, David, Stephan, David, Szabat}, Kathryn},
booktitle = {Technometrics},
edition = {8},
file = {:E$\backslash$:/Reference/Maths/Probability and Statistics/1{\_}Probabilty and Statistics Books/2{\_}Statistics-for-Managers-using-Microsoft-Excel.pdf:pdf},
isbn = {9789332585744},
number = {2},
pages = {808},
publisher = {Pearson India Education},
title = {{Statistics for Managers Using Microsoft {\textregistered} Excel}},
year = {2017}
}
@article{Jigsaw_Puzzles,
archivePrefix = {arXiv},
arxivId = {arXiv:1603.09246v3},
author = {Noroozi, Mehdi and Favaro, Paolo},
eprint = {arXiv:1603.09246v3},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Literature/1{\_}Citation{\_}Papers/Unsupervised learning of visual.pdf:pdf},
title = {{Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles}}
}
@book{bishop2016pattern,
abstract = {The kinetics of Ru(III)-nicotinic acid complex formation by oxidation of bromamine-T (p-CH3C6H4SO2NBrNa) in acid solution at 35°C has been studied spectrophotometricaolly at $\lambda$max 585 nm. The reaction rate shows first order dependencee on bromamine-T, a fractional order dependence on [nicotinic acid] and second order with respect to [Ru(III)]. The reaction is inverse 1.5 order on [H +] and also inverse second order on [Cl-], The variation of ionic strength, dielectric constant of the medium and the reaction product of BAT, p-toluene sulphonamide have no effect on the reaction. Activation parameters have been evaluated from the Arrhenius plot. A mechanism consistent with experimental results has been proposed.},
author = {Kondarasaiah, M. H. and Ananda, S.},
booktitle = {Oxidation Communications},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Literature/1{\_}Citation{\_}Papers/Bishop - Pattern Recognition And Machine Learning - Springer  2006.pdf:pdf},
isbn = {9780387310732},
issn = {02094541},
keywords = {Acid medium,Bromamine-T,Oxidation,Ru(III)-nicotinic acid complex formation},
number = {1},
pages = {140--147},
title = {{Kinetic and mechanistic study of Ru(III)-nicotinic acid complex formation by oxidation of bromamine-T in acid solution}},
volume = {27},
year = {2004}
}
@book{Hands_On_ML,
abstract = {Through a series of recent breakthroughs, deep learning has boosted the entire field of machine learning. Now, even programmers who know close to nothing about this technology can use simple, efficient tools to implement programs capable of learning from data. This practical book shows you how. Using concrete examples, minimal theory, and two production-ready Python frameworks—scikit-learn and TensorFlow—author Aur{\'{e}}lien G{\'{e}}ron helps you gain an intuitive understanding of the concepts and tools for building intelligent systems. You'll learn a range of techniques, starting with simple linear regression and progressing to deep neural networks.},
author = {G{\'{e}}ron, Aur{\'{e}}lien},
file = {:C$\backslash$:/Users/USER/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Scikit-learn, Scikit- - Unknown - Hands-On Machine Learning with Scikit-Learn and TensorFlow.pdf:pdf},
isbn = {9781491962299},
pages = {1--4},
publisher = {O'Reilly Media},
title = {{Hands-On Machine Learning with Scikit-Learn and TensorFlow}}
}
@article{DCASE,
abstract = {An increasing number of researchers work in computational auditory scene analysis (CASA). However, a set of tasks, each with a well-defined evaluation framework and commonly used datasets do not yet exist. Thus, it is difficult for results and algorithms to be compared fairly, which hinders research on the field. In this paper we will introduce a newly-launched public evaluation challenge dealing with two closely related tasks of the field: acoustic scene classification and event detection. We give an overview of the tasks involved; describe the processes of creating the dataset; and define the evaluation metrics. Finally, illustrations on results for both tasks using baseline methods applied on this dataset are presented, accompanied by open-source code. {\textcopyright} 2013 EURASIP.},
author = {Giannoulis, Dimitrios and Stowell, Dan and Benetos, Emmanouil and Rossignol, Mathias and Lagrange, Mathieu and Plumbley, Mark D.},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Papers/Audio Data Sets/DCASE{\_}EUSIPCO13.pdf:pdf},
isbn = {9780992862602},
issn = {22195491},
journal = {European Signal Processing Conference},
keywords = {Computational auditory scene analysis,acoustic event detection,acoustic scene classification},
title = {{A database and challenge for acoustic scene classification and event detection}},
year = {2013}
}
@article{SoundNet,
archivePrefix = {arXiv},
arxivId = {arXiv:1610.09001v1},
author = {Torralba, Antonio},
eprint = {arXiv:1610.09001v1},
file = {:C$\backslash$:/Users/USER/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Torralba - 2016 - SoundNet Learning Sound Representations from Unlabeled Video.pdf:pdf},
number = {Nips},
title = {{SoundNet : Learning Sound Representations from Unlabeled Video}},
year = {2016}
}
@article{Adam,
abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
archivePrefix = {arXiv},
arxivId = {1412.6980},
author = {Kingma, Diederik P. and Ba, Jimmy Lei},
eprint = {1412.6980},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Papers/1{\_}Citation{\_}Papers/Adam.pdf:pdf},
journal = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
pages = {1--15},
title = {{Adam: A method for stochastic optimization}},
year = {2015}
}
@article{CNN_2,
abstract = {The ability of deep convolutional neural networks (CNNs) to learn discriminative spectro-temporal patterns makes them well suited to environmental sound classification. However, the relative scarcity of labeled data has impeded the exploitation of this family of high-capacity models. This study has two primary contributions: first, we propose a deep CNN architecture for environmental sound classification. Second, we propose the use of audio data augmentation for overcoming the problem of data scarcity and explore the influence of different augmentations on the performance of the proposed CNN architecture. Combined with data augmentation, the proposed model produces state-of-the-art results for environmental sound classification. We show that the improved performance stems from the combination of a deep, high-capacity model and an augmented training set: this combination outperforms both the proposed CNN without augmentation and a 'shallow' dictionary learning model with augmentation. Finally, we examine the influence of each augmentation on the model's classification accuracy for each class, and observe that the accuracy for each class is influenced differently by each augmentation, suggesting that the performance of the model could be improved further by applying class-conditional data augmentation.},
archivePrefix = {arXiv},
arxivId = {1608.04363},
author = {Salamon, Justin and Bello, Juan Pablo},
doi = {10.1109/LSP.2017.2657381},
eprint = {1608.04363},
file = {:C$\backslash$:/Users/USER/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Salamon, Bello - 2017 - Deep Convolutional Neural Networks and Data Augmentation for Environmental Sound Classification.pdf:pdf},
issn = {10709908},
journal = {IEEE Signal Processing Letters},
keywords = {Deep convolutional neural networks (CNNs),deep learning,environmental sound classification,urban sound dataset},
number = {3},
pages = {279--283},
title = {{Deep Convolutional Neural Networks and Data Augmentation for Environmental Sound Classification}},
volume = {24},
year = {2017}
}
@article{Adversarial_Leraning,
archivePrefix = {arXiv},
arxivId = {arXiv:1605.09782v7},
author = {Donahue, Jeff and Darrell, Trevor},
eprint = {arXiv:1605.09782v7},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Literature/1{\_}Citation{\_}Papers/Adversarial feature.pdf:pdf},
number = {2016},
pages = {1--18},
title = {{Adversarial Feature Learning}},
year = {2017}
}
@article{Dataset_Kinetics,
abstract = {We describe the DeepMind Kinetics human action video dataset. The dataset contains 400 human action classes, with at least 400 video clips for each action. Each clip lasts around 10s and is taken from a different YouTube video. The actions are human focussed and cover a broad range of classes including human-object interactions such as playing instruments, as well as human-human interactions such as shaking hands. We describe the statistics of the dataset, how it was collected, and give some baseline performance figures for neural network architectures trained and tested for human action classification on this dataset. We also carry out a preliminary analysis of whether imbalance in the dataset leads to bias in the classifiers.},
archivePrefix = {arXiv},
arxivId = {1705.06950},
author = {Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and Suleyman, Mustafa and Zisserman, Andrew},
eprint = {1705.06950},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Literature/1{\_}Citation{\_}Papers/Kinetic.pdf:pdf},
title = {{The Kinetics Human Action Video Dataset}},
url = {http://arxiv.org/abs/1705.06950},
year = {2017}
}
@book{Subramaniam1997,
abstract = {BACKGROUND: Pediatric patients' self-report of health-related quality of life (HRQOL) has emerged as an important patient-based health outcome. A practical, validated generic measure of HRQOL facilitates assessing risk, tracking health status, and measuring treatment outcomes in pediatric populations. METHODS: The PedsQL is a brief, standardized, generic assessment instrument that systematically assesses patients' and parents' perceptions of HRQOL in pediatric patients with chronic health conditions using pediatric cancer as an exemplary model. The PedsQL is based on a modular approach to measuring HRQOL and consists of a 15-item core measure of global HRQOL and eight supplemental modules assessing specific symptom or treatment domains. The PedsQL was empirically derived from data collected from 291 pediatric cancer patients and their parents at various stages of treatment. RESULTS: Both reliability and validity were determined. Cronbach's alpha coefficients for the core measure (alpha = .83 for patient and alpha = .86 for parent) were acceptable for group comparisons. Alphas for the patient self-report modules generally ranged from .70 to .89. Discriminant or clinical validity, using the known-groups approach, was demonstrated for patients on- versus off-treatments. The 11 scales showed small-to-medium positive intercorrelations, supporting the multidimensional measurement model. Further construct validity was demonstrated via a multimethod-multitrait matrix using standardized psychosocial questionnaires. CONCLUSION: The results support the PedsQL as a reliable and valid measure of HRQOL. The PedsQL core and modular design makes it flexible enough to be used in a variety of research and clinical applications for pediatric chronic health conditions.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Subramaniam, Amos Gilat Vish},
booktitle = {Journal of Wind Engineering and Industrial Aerodynamics},
doi = {10.1016/S0167-6105(97)00227-4},
eprint = {arXiv:1011.1669v3},
isbn = {978-0534407612},
issn = {01676105},
pmid = {10024117},
title = {{Numerical Methods for Engineers and Scientists An Introduction with Applications using MATLAB{\textregistered}}},
year = {1997}
}
@article{Autopool,
abstract = {Sound event detection (SED) methods are tasked with labeling segments of audio recordings by the presence of active sound sources. SED is typically posed as a supervised machine learning problem, requiring strong annotations for the presence or absence of each sound source at every time instant within the recording. However, strong annotations of this type are both labor- and cost-intensive for human annotators to produce, which limits the practical scalability of SED methods. In this paper, we treat SED as a multiple instance learning (MIL) problem, where training labels are static over a short excerpt, indicating the presence or absence of sound sources but not their temporal locality. The models, however, must still produce temporally dynamic predictions, which must be aggregated (pooled) when comparing against static labels during training. To facilitate this aggregation, we develop a family of adaptive pooling operators - referred to as autopool - which smoothly interpolate between common pooling operators, such as min-, max-, or average-pooling, and automatically adapt to the characteristics of the sound sources in question. We evaluate the proposed pooling operators on three datasets, and demonstrate that in each case, the proposed methods outperform nonadaptive pooling operators for static prediction, and nearly match the performance of models trained with strong, dynamic annotations. The proposed method is evaluated in conjunction with convolutional neural networks, but can be readily applied to any differentiable model for time-series label prediction. While this paper focuses on SED applications, the proposed methods are general, and could be applied widely to MIL problems in any domain.},
archivePrefix = {arXiv},
arxivId = {1804.10070},
author = {McFee, Brian and Salamon, Justin and Bello, Juan Pablo},
doi = {10.1109/TASLP.2018.2858559},
eprint = {1804.10070},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Papers/1{\_}Citation{\_}Papers/AutoPool.pdf:pdf},
issn = {23299290},
journal = {IEEE/ACM Transactions on Audio Speech and Language Processing},
keywords = {Sound event detection,deep learning,machine learning,multiple instance learning},
number = {11},
pages = {2180--2193},
title = {{Adaptive Pooling Operators for Weakly Labeled Sound Event Detection}},
volume = {26},
year = {2018}
}
@book{Devore2010,
author = {Devore, Jay},
edition = {8},
file = {:E$\backslash$:/Reference/Maths/Probability and Statistics/1{\_}Probabilty and Statistics Books/1.0{\_}probability{\_}and{\_}statistics{\_}for{\_}engineering{\_}and{\_}the{\_}sciences.pdf:pdf},
isbn = {13: 978-0-538-73352-6},
pages = {776},
publisher = {Richard Stratton},
title = {{Probability and Statistics for Engineering and the Sciences}},
year = {2010}
}
@book{Rao2009,
abstract = {Technology/Engineering/Mechanical. Helps you move from theory to optimizing engineering systems in almost any industry. Now in its Fourth Edition, Professor Singiresu Rao's acclaimed text Engineering Optimization enables readers to quickly master and apply all the important optimization methods in use today across a broad range of industries. Covering both the latest and classical optimization methods, the text starts off with the basics and then progressively builds to advanced principles and applications. This comprehensive text covers nonlinear, linear, geometric, dynamic, and stochastic programming techniques as well as more specialized methods such as multiobjective, genetic algorithms, simulated annealing, neural networks, particle swarm optimization, ant colony optimization, and fuzzy optimization. Each method is presented in clear, straightforward language, making even the more sophisticated techniques easy to grasp. Moreover, the author provides: Case examples that show how each method is applied to solve real-world problems across a variety of industries. Review questions and problems at the end of each chapter to engage readers in applying their newfound skills and knowledge. Examples that demonstrate the use of MATLAB{\textregistered} for the solution of different types of practical optimization problems. References and bibliography at the end of each chapter for exploring topics in greater depth. Answers to Review Questions available on the author's Web site to help readers to test their understanding of the basic concepts. With its emphasis on problem-solving and applications, Engineering Optimization is ideal for upper-level undergraduates and graduate students in mechanical, civil, electrical, chemical, and aerospace engineering. In addition, the text helps practicing engineers in almost any industry design improved, more efficient systems at less cost. {\textcopyright} 2009 John Wiley {\&} Sons, Inc.},
author = {Rao, Singiresu S.},
booktitle = {Engineering Optimization: Theory and Practice: Fourth Edition},
doi = {10.1002/9780470549124},
file = {:C$\backslash$:/Users/USER/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rao - 2009 - Engineering Optimization Theory and Practice Fourth Edition.pdf:pdf},
isbn = {9780470183526},
keywords = {ISBN-13:    9780470183526},
pages = {1--813},
title = {{Engineering Optimization: Theory and Practice: Fourth Edition}},
year = {2009}
}
@article{Audio2Vec,
author = {Tagliasacchi, Marco and Gfeller, Beat and Quitry, F{\'{e}}lix De Chaumont and Roblek, Dominik},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/Stage{\_}Cense{\_}2020/Presentation{\_}Audio2Vec/Audio2Vec.pdf:pdf},
journal = {IEEE Signal Processing Letters},
title = {{Learning audio representations with self-supervision}},
year = {2020}
}
@article{VGG,
abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3 × 3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16–19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
archivePrefix = {arXiv},
arxivId = {1409.1556},
author = {Simonyan, Karen and Zisserman, Andrew},
eprint = {1409.1556},
file = {:C$\backslash$:/Users/USER/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Simonyan, Zisserman - 2015 - Very deep convolutional networks for large-scale image recognition(2).pdf:pdf},
journal = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
pages = {1--14},
title = {{Very deep convolutional networks for large-scale image recognition}},
year = {2015}
}
@article{batch_normalization,
abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82{\%} top-5 test error, exceeding the accuracy of human raters.},
archivePrefix = {arXiv},
arxivId = {1502.03167},
author = {Ioffe, Sergey and Szegedy, Christian},
eprint = {1502.03167},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Papers/1{\_}Citation{\_}Papers/Batch{\_}Norm.pdf:pdf},
isbn = {9781510810587},
journal = {32nd International Conference on Machine Learning, ICML 2015},
pages = {448--456},
title = {{Batch normalization: Accelerating deep network training by reducing internal covariate shift}},
volume = {1},
year = {2015}
}
@article{Handwritten_digit_recognition,
author = {{Y. Le Cun}, B. Boser},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Literature/1{\_}Citation{\_}Papers/lecun-90c.pdf:pdf},
title = {{Handwritten Digit Recognition with a Back-Propagation Network}}
}
@article{CNN,
abstract = {Convolutional Neural Networks (CNNs) have proven very effective in image classification and show promise for audio. We use var-ious CNN architectures to classify the soundtracks of a dataset of 70M training videos (5.24 million hours) with 30,871 video-level la-bels. We examine fully connected Deep Neural Networks (DNNs), AlexNet [1], VGG [2], Inception [3], and ResNet [4]. We investigate varying the size of both training set and label vocabulary, finding that analogs of the CNNs used in image classification do well on our au-dio classification task, and larger training and label sets help up to a point. A model using embeddings from these classifiers does much better than raw features on the Audio Set [5] Acoustic Event Detec-tion (AED) classification task.},
author = {Hershey, Shawn and Chaudhuri, Sourish and Ellis, Daniel P W and Gemmeke, Jort F and Jansen, Aren and Moore, R Channing and Plakal, Manoj and Platt, Devin and Saurous, Rif A and Seybold, Bryan and Slaney, Malcolm and Weiss, Ron J and Wilson, Kevin and York, New and View, Mountain},
file = {:C$\backslash$:/Users/USER/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hershey et al. - 2017 - CNN ARCHITECTURES FOR LARGE-SCALE AUDIO CLASSIFICATION Shawn Hershey, Sourish Chaudhuri, Daniel P. W. Ellis, Jor.pdf:pdf},
isbn = {9781509041176},
journal = {IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2017},
pages = {131--135},
title = {{CNN ARCHITECTURES FOR LARGE-SCALE AUDIO CLASSIFICATION Shawn Hershey, Sourish Chaudhuri, Daniel P. W. Ellis, Jort F. Gemmeke, Aren Jansen, R. Channing Moore, Manoj Plakal, Devin Platt, Rif A. Saurous, Bryan Seybold, Malcolm Slaney, Ron J. Weiss, Kevin Wil}},
year = {2017}
}
@article{Royo2019,
abstract = {Lidar imaging systems are one of the hottest topics in the optronics industry. The need to sense the surroundings of every autonomous vehicle has pushed forward a race dedicated to deciding the final solution to be implemented. However, the diversity of state-of-the-art approaches to the solution brings a large uncertainty on the decision of the dominant final solution. Furthermore, the performance data of each approach often arise from different manufacturers and developers, which usually have some interest in the dispute. Within this paper, we intend to overcome the situation by providing an introductory, neutral overview of the technology linked to lidar imaging systems for autonomous vehicles, and its current state of development. We start with the main single-point measurement principles utilized, which then are combined with different imaging strategies, also described in the paper. An overview of the features of the light sources and photodetectors specific to lidar imaging systems most frequently used in practice is also presented. Finally, a brief section on pending issues for lidar development in autonomous vehicles has been included, in order to present some of the problems which still need to be solved before implementation may be considered as final. The reader is provided with a detailed bibliography containing both relevant books and state-of-the-art papers for further progress in the subject.},
author = {Royo, Santiago and Ballesta-Garcia, Maria},
doi = {10.3390/app9194093},
file = {:E$\backslash$:/1{\_}Master Feuilles et Documents/PHD{\_}Offers/UK/An Overview of Lidar Imaging Systems.pdf:pdf},
issn = {20763417},
journal = {Applied Sciences (Switzerland)},
keywords = {3D imaging,Autonomous vehicles,Ladar,Lasers,Lidar,MEMS,Photodetectors,Point cloud,Scanners,Self-driving car,Time of flight},
number = {19},
title = {{An overview of lidar imaging systems for autonomous vehicles}},
volume = {9},
year = {2019}
}
@book{Matlab_Deep_Learning,
abstract = {Get started with MATLAB for deep learning and AI with this in-depth primer. In this book, you start with machine learning fundamentals, then move on to neural networks, deep learning, and then convolutional neural networks. In a blend of fundamentals and applications, MATLAB Deep Learning employs MATLAB as the underlying programming language and tool for the examples and case studies in this book. With this book, you'll be able to tackle some of today's real world big data, smart bots, and other complex data problems. You'll see how deep learning is a complex and more intelligent aspect of machine learning for modern smart data analysis and usage. What You'll Learn Use MATLAB for deep learning Discover neural networks and multi-layer neural networks Work with convolution and pooling layers Build a MNIST example with these layers Who This Book Is For Those who want to learn deep learning using MATLAB. Some MATLAB experience may be useful.},
author = {Kim, Phil},
booktitle = {MATLAB Deep Learning},
doi = {10.1007/978-1-4842-2845-6},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Papers/MATLAB{\_}Deep{\_}Learning{\_}With{\_}Machine{\_}Learni.pdf:pdf},
isbn = {9781484228449},
publisher = {Apress},
title = {{MATLAB Deep Learning}},
year = {2017}
}
@article{L3_design_param,
author = {Cramer, Jason and Wu, Ho-hsiang and Salamon, Justin and Bello, Juan Pablo},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Papers/1{\_}L{\_}3{\_}Net{\_}Design{\_}Parameters.pdf:pdf},
isbn = {9781538646588},
pages = {609--617},
title = {{Look , Listen , and Learn More :}},
url = {http://www.justinsalamon.com/uploads/4/3/9/4/4394963/cramer{\_}looklistenlearnmore{\_}icassp{\_}2019.pdf},
year = {2019}
}
@article{PCEN,
abstract = {Robust and far-field speech recognition is critical to enable true hands-free communication. In far-field conditions, signals are attenuated due to distance. To improve robustness to loudness variation, we introduce a novel frontend called per-channel energy normalization (PCEN). The key ingredient of PCEN is the use of an automatic gain control based dynamic compression to replace the widely used static (such as log or root) compression. We evaluate PCEN on the keyword spotting task. On our large rerecorded noisy and far-field eval sets, we show that PCEN significantly improves recognition performance. Furthermore, we model PCEN as neural network layers and optimize high-dimensional PCEN parameters jointly with the keyword spotting acoustic model. The trained PCEN frontend demonstrates significant further improvements without increasing model complexity or inference-time cost.},
archivePrefix = {arXiv},
arxivId = {1607.05666},
author = {Wang, Yuxuan and Getreuer, Pascal and Hughes, Thad and Lyon, Richard F. and Saurous, Rif A.},
doi = {10.1109/ICASSP.2017.7953242},
eprint = {1607.05666},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Papers/PCEN.pdf:pdf},
isbn = {9781509041176},
issn = {15206149},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
keywords = {automatic gain control,deep neural networks,robust and far-field speech recognition},
number = {1},
pages = {5670--5674},
title = {{Trainable frontend for robust and far-field keyword spotting}},
year = {2017}
}
@article{ASC,
abstract = {In this article we present an account of the state-of-the-art in acoustic scene classification (ASC), the task of classifying environments from the sounds they produce. Starting from a historical review of previous research in this area, we define a general framework for ASC and present different imple- mentations of its components. We then describe a range of different algorithms submitted for a data challenge that was held to provide a general and fair benchmark for ASC techniques. The dataset recorded for this purpose is presented, along with the performance metrics that are used to evaluate the algorithms and statistical significance tests to compare the submitted methods. We use a baseline method that employs MFCCS, GMMS and a maximum likelihood criterion as a benchmark, and only find sufficient evidence to conclude that three algorithms significantly outperform it. We also evaluate the human classification accuracy in performing a similar classification task. The best performing algorithm achieves a mean accuracy that matches the median accuracy obtained by humans, and common pairs of classes are misclassified by both computers and humans. However, all acoustic scenes are correctly classified by at least some individuals, while there are scenes that are misclassified by all algorithms.},
archivePrefix = {arXiv},
arxivId = {1411.3715},
author = {Barchiesi, Daniele and Giannoulis, Dimitrios and Stowell, Dan and Plumbley, Mark D.},
doi = {10.1109/MSP.2014.2326181},
eprint = {1411.3715},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Papers/Sound Features/Acoustic Scene Classification.pdf:pdf},
title = {{Acoustic Scene Classification}},
url = {http://arxiv.org/abs/1411.3715{\%}0Ahttp://dx.doi.org/10.1109/MSP.2014.2326181},
year = {2014}
}
@book{AI_Russel,
abstract = {The long-anticipated revision of this {\#}1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications. Intelligent Agents. Solving Problems by Searching. Informed},
archivePrefix = {arXiv},
arxivId = {arXiv:gr-qc/9809069v1},
author = {Russell, Stuart J and Norvig, Peter},
booktitle = {Pearson},
doi = {10.1017/S0269888900007724},
eprint = {9809069v1},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Literature/1{\_}Citation{\_}Papers/Artificial Intelligance{\_}A Modern Approach.pdf:pdf},
isbn = {9780136042594},
issn = {0269-8889},
pages = {1151},
pmid = {20949757},
primaryClass = {arXiv:gr-qc},
title = {{Artificial Intelligence A Modern Approach; PearsonEducation}},
year = {2003}
}
@article{Heath1997,
abstract = {We introduce a definition of Grid computing which is adhered to throughout this Theme Issue. We compare the evolution of the World Wide Web with current aspirations for Grid computing and indicate areas that need further research and development before a generally usable Grid infrastructure becomes available. We discuss work that has been done in order to make scientific Grid computing a viable proposition, including the building of Grids, middleware developments, computational steering and visualization. We review science that has been enabled by contemporary computational Grids, and associated progress made through the widening availability of high performance computing.},
author = {Heath, Michael T.},
doi = {10.1098/rsta.2005.1632},
isbn = {0-07-239910-4},
issn = {1364-503X},
journal = {Philosophical transactions. Series A, Mathematical, physical, and engineering sciences},
keywords = {Biological,Computer Simulation,Informatics,Informatics: methods,Informatics: trends,International Cooperation,Internet,Mathematical Computing,Models,Research,Research Design,Research: trends,Science,Science: methods,Science: trends,Software,Software: trends,Systems Integration},
pmid = {16099742},
title = {{SCIENTIFIC COMPUTING An Introductory Survey}},
year = {1997}
}
@article{SONYC_UST,
author = {Cartwright, Mark and Elisa, Ana and Mendez, Mendez and Cramer, Jason and Lostanlen, Vincent and Dove, Graham and Wu, Ho-hsiang and Salamon, Justin and Nov, Oded and Bello, Juan Pablo},
file = {:C$\backslash$:/Users/USER/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cartwright et al. - 2019 - SONYC URBAN SOUND TAGGING ( SONYC-UST ) A MULTILABEL DATASET FROM AN URBAN ACOUSTIC SENSOR NETWORK Center for.pdf:pdf},
number = {October},
pages = {35--39},
title = {{SONYC URBAN SOUND TAGGING ( SONYC-UST ): A MULTILABEL DATASET FROM AN URBAN ACOUSTIC SENSOR NETWORK Center for Urban Science and Progress , New York University , NY , USA Department of Computer Science and Engineering , New York University , NY , USA Corn}},
year = {2019}
}
@article{HMM_ASC,
author = {Challenge, Ieee Aasp and Scenes, Acoustic},
file = {:E$\backslash$:/2{\_}Master Sujets et Matieres/M2{\_}Project/Presentation{\_}and{\_}Report/Report{\_}M2{\_}Project/Literature/1{\_}Citation{\_}Papers/HMM{\_}ASC.pdf:pdf},
number = {3},
pages = {3--5},
title = {{IEEE AASP SCENE CLASSIFICATION CHALLENGE USING HIDDEN MARKOV MODELS AND FRAME BASED CLASSIFICATION May Chum , Ariel Habshush , Abrar Rahman , Christopher Sang The Cooper Union Electrical Engineering Department 41 Cooper Square New York , NY 10003}}
}
